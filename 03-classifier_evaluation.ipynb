{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Evaluation\n",
    "\n",
    "In this notebook we test a bunch of different classifiers in order to find the 3 best performing one. Those three will then be combined in an ensemble model to form our final classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('./lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.metrics import log_loss, classification_report, accuracy_score\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.definitions import RANDOM_SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "import numpy.random\n",
    "numpy.random.seed(RANDOM_SEED)\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(RANDOM_SEED)\n",
    "\n",
    "import tensorflow\n",
    "tensorflow.set_random_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.definitions import SPLITS_BASE_PATH\n",
    "\n",
    "SPLITS_BASE_PATH.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the top 3 best performing classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating \"Random Forest\"\n",
      "[Took 0.9301531314849854s]\n",
      "\n",
      "Evaluating \"XGBoost\"\n",
      "[Took 0.10933399200439453s]\n",
      "\n",
      "Evaluating \"K-Nearest Neighbour\"\n",
      "[Took 0.38782691955566406s]\n",
      "\n",
      "Evaluating \"Naive Bayes\"\n",
      "[Took 0.04604482650756836s]\n",
      "\n",
      "Evaluating \"Quadratic Discriminant Analysis\"\n",
      "[Took 0.05256295204162598s]\n",
      "\n",
      "Evaluating \"Adaptive Boosting\"\n",
      "[Took 0.24199175834655762s]\n",
      "\n",
      "Evaluating \"Multilayer Perceptron\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marc/miniconda2/envs/xai_test/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/marc/miniconda2/envs/xai_test/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Took 0.45665717124938965s]\n",
      "\n",
      "Evaluating \"Deep Neural Network\"\n",
      "WARNING:tensorflow:From /Users/marc/miniconda2/envs/xai_test/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marc/miniconda2/envs/xai_test/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/marc/miniconda2/envs/xai_test/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "[Took 2.670112133026123s]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lib.dataset import load_split, evaluate_estimator, evaluate_splits\n",
    "from lib.classifiers import classifier_factories\n",
    "\n",
    "results = {}\n",
    "\n",
    "for (name, factory) in classifier_factories.items():\n",
    "    t0 = time.time()\n",
    "    print(f'Evaluating \"{name}\"')\n",
    "    scores = evaluate_splits(factory)\n",
    "    duration = time.time() - t0\n",
    "    print(f'[Took {duration}s]\\n')\n",
    "    \n",
    "    results[name] = {\n",
    "        'scores': scores,\n",
    "        'duration': duration\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Random Forest': {'scores': [0.7888888888888889,\n",
       "   0.8111111111111111,\n",
       "   0.8777777777777778],\n",
       "  'duration': 0.9301531314849854},\n",
       " 'XGBoost': {'scores': [0.7444444444444445,\n",
       "   0.7777777777777778,\n",
       "   0.8666666666666667],\n",
       "  'duration': 0.10933399200439453},\n",
       " 'K-Nearest Neighbour': {'scores': [0.5666666666666667,\n",
       "   0.6888888888888889,\n",
       "   0.6111111111111112],\n",
       "  'duration': 0.38782691955566406},\n",
       " 'Naive Bayes': {'scores': [0.8333333333333334,\n",
       "   0.8444444444444444,\n",
       "   0.8777777777777778],\n",
       "  'duration': 0.04604482650756836},\n",
       " 'Quadratic Discriminant Analysis': {'scores': [0.7888888888888889,\n",
       "   0.8111111111111111,\n",
       "   0.8555555555555555],\n",
       "  'duration': 0.05256295204162598},\n",
       " 'Adaptive Boosting': {'scores': [0.7111111111111111,\n",
       "   0.7555555555555555,\n",
       "   0.8444444444444444],\n",
       "  'duration': 0.24199175834655762},\n",
       " 'Multilayer Perceptron': {'scores': [0.7555555555555555,\n",
       "   0.7555555555555555,\n",
       "   0.8666666666666667],\n",
       "  'duration': 0.45665717124938965},\n",
       " 'Deep Neural Network': {'scores': [0.5777777777777777,\n",
       "   0.5555555555555556,\n",
       "   0.4444444444444444],\n",
       "  'duration': 2.670112133026123}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 3 best performing classifiers are: Random Forest, Naive Bayes and Quadratic Discriminant Analysis. In the next section we are going to create an ensemble classifier out of those 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_classifiers = [\n",
    "    'Random Forest',\n",
    "    'Naive Bayes',\n",
    "    'Quadratic Discriminant Analysis'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble the Ensemble Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating \"Ensemble Classifier\"\n",
      "[Took 2.948072910308838s]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7888888888888889, 0.8333333333333334, 0.8888888888888888]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_ensemble_estimator(verbose, random_state, n_jobs):\n",
    "    from sklearn.ensemble import VotingClassifier\n",
    "    estimators = list(\n",
    "                map(\n",
    "                    lambda name: (name, classifier_factories[name](verbose=verbose, random_state=RANDOM_SEED, n_jobs=-1)),\n",
    "                    best_classifiers))\n",
    "\n",
    "    return VotingClassifier(estimators, voting='soft')\n",
    "\n",
    "print(f'Evaluating \"Ensemble Classifier\"')\n",
    "t0 = time.time()\n",
    "scores = evaluate_splits(create_ensemble_estimator)\n",
    "duration = time.time() - t0\n",
    "print(f'[Took {duration}s]\\n')\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classifier is now able to achive an accuracy of about 0.88, which is better than each single classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
